無駄だと思った箇所 by presentation practice Feb 1
3．が長すぎるから短く
    獲得関数のどうやって紹介するか

 初めに，問題の背景などについて説明し，その後，ベイズ最適化を紹介します．
 さらに，提案手法について紹介した後，実験した結果を述べて，まとめを行います．

1． 例として〜を考える
    ある材料からロボットを開発し，作られたロボットが壊れるまでの耐久時間を考える
    それを，入力と出力，その間を関連づける関数として考える
    このような関数を考えたときに，
    この関数を最適とする入力xを見つける問題を考えます

    ロボットの耐久時間と言った点で
    最適なロボットの開発の行うための材料を見つける問題

ロボット開発をどのように考えるか
    ⇨ブラックボックス関数
                    
2．
ブラックボックス関数を解くには？
    ⇨ベイズ最適化



3．
    ロボットの開発の例の場合，ロボットを開発するには
    時間的コストや金銭的コストがかかる

ベイズ最適化を効率的に解きたい
⇨適切な獲得関数を選択することで効率の良いベイズ最適化が実現可能に

4．

5．低いコストで耐久時間が長いロボットの材料を求めたい
⇨ブラックボックス関数fを具体的にどのように考えるか？

・6
                                        ガウス過程回帰は、与えられた訓練データに基づいて、目的関数の予測分布を求める手法である。
                                        一方、ガウス過程に基づくベイズ最適化は、予測分布に基づいて、目的関数の最適な入力を決定する手法である。
                                        両者の違いは、目的が異なることである。ガウス過程回帰は、目的関数の予測分布を求めることであり、
                                        ベイズ最適化は、目的関数の最適な入力を決定することである。
                                        (by ChatGPT)(これは想定質問用に入れておく(ここには定義とか説明事項とかを入れておく))

7．
次の点を選ぶ指標が何か？
⇨次に選ぶ点を詳しく説明します

8．

argmax α(x): αが最大となる引数x　!!!!!!!!!!Feb2

⇨従来の獲得関数について見ていきましょう

・9
活用中心(局所解に陥りやすい)
探索中心(最適解に辿り着くまでに時間を要する)

⇨そこで，私たちは新しい獲得関数を提案します



10．
⇨このGP-UCBを用いたアルゴリズムをみていきましょう

11．

            このアルゴリズムは、ガウス過程に基づいたベイズ最適化アルゴリズムです。

入力として、入力空間D、GP事前分布μ0=0、σ0、kが与えられます。

次に、for文を使って反復処理を行います。

            tが1から始まり、2,3,4...と増加します。

そして、Dからxを選択し、それが目的関数fの最大値を取る点であるように選びます。

！！！そして、その点に対応する値ytを求め、ベイズ更新を行い、最終的な予測分布μtとσtを得ます。

最後に、反復処理を終了し、最適な点を求めます。

12．
                    cumulative regretとは，評価対象の関数の最大値と各反復tで選択された値との差を表す指標である．
!!!!!!!!!ある時点（T）までの!!!!!!!!!!最大値（f（x*））と各反復tで選択された値（f（xt））の差の総和として計算される。
                    
                    Average Regretはcumulative regretを反復回数Tで割ったものである。
                    これは、最大値と各反復で選択された値との間の平均的な差を表しています。

                    Mean Average Regretは、全施行におけるAverage Regretの平均値である。
                    これは複数の試行にわたる選択プロセスの平均的なパフォーマンスを表し、
                    単一の試行の平均後悔よりもロバストなパフォーマンス指標となります。

                    ！！！！Mean Average Regretが低いほど、獲得した関数の性能が高い、
                    つまり真の最適解に近づいていることを意味します。



Mean Average Regret (MAR)は、結果として得られる平均の「後悔」を表します。
MARが低い場合は、最適な選択肢を頻繁に選んでいることを示します。
MARは，その値が低いほど，獲得した関数の性能が高いことがわかる指標となります

⇨次に実験対象データを見ていきましょう


13．

14．
　低いほど、獲得した関数の性能が高い，Mean Average Regret


p.1の説明方法を詰める
p.2ブラックボックス関数の誤差の読み方　epsilon
p.3をできるだけ少ない言葉で説明する
p.7最適な点を次に観測して，訓練データに"加える"で良いのか
p.9の活用と探索に相当する箇所の説明の暗記
p.10の説明を簡潔にできないか
p.12Mean Average Regretの説明をもっと分かりやすく







・7~8
    最適な点を具体的

・8~9
従来の獲得関数

・事後分布のパラメータ推定
    複雑なモデルだと，事後分布のパラメータ(正規分布の平均とか分散に相当するもの)推定が難しい
    (複雑なモデルだと，パラメータが近似的にしか求められない場合がある)(直接計算できずに，面倒な方法しかパラメータがもとまらない場合がある)
    今回のガウス過程回帰では，訓練データさえ与えられれば，書いてある式通りに計算すればパラメータがわかる!
    (ガウス過程回帰のメリット)




・p.5
    ロボットの話を混ぜて説明した方がわかりやすい
    
・p.6
    ガウス過程回帰を用いることで，解析的にデータから関数を予測することができた
    
・p.10
    下は，見なくても説明できる時間がなければ省略可能

・p.11











p8の探索の説明を探索重視の時と入れる？







    ・発表の一例



　オレンジ部分が提案手法の獲得関数であるという
(そうすることで，今回のGP-UCBを用いてxを選んでいるということを明示できる)

・p.12で，
    MeanAverageRegretの直感的説明をして，低い方が良いことを説明する
    (これは，最適な点を選んでいることを示している)

    (ChatGPT)Mean Average Regret (MAR)は、結果として得られる平均の「後悔」を表します。これは、最適な選択肢を選んでいなかった場合に、どの程度の「損失」が生じるかを示します。 MARが低い場合は、最適な選択肢を頻繁に選んでいることを示します。

・p.13
    このページは時間を見て，端折るかどうかを決める(14を適切なタイミングで入れるように)


・各ページの訴求ポイントとなる箇所を明示(単語レベルで良い気がする)


・締めとはじめの言葉を考える!
p.14
MPI

後一個


3 獲得関数の説明



13 交通データ

